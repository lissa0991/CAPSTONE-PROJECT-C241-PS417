# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KIXxJZVgMULKFPZUqafjx8p06B-kt4At
"""

import pandas as pd
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import os

# Define the path to the dataset
dataset_path = '/content/dataset-ayam.csv'  # Replace with the actual CSV file name

# Load the dataset
data = pd.read_csv(dataset_path)

# Display the first few rows and columns of the dataset to understand its structure
print(data.head())
print(data.columns)

# Feature selection - select relevant features for clustering
# We will use the 'Loves' column for clustering
features = ['Loves']  # Replace with actual feature names if available

# Ensure the selected feature columns exist in the dataset
X = data[features]

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Determine the optimal number of clusters using the elbow method
inertia = []
K = range(1, 11)
for k in K:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    inertia.append(kmeans.inertia_)

# Plot the elbow curve
plt.figure(figsize=(8, 6))
plt.plot(K, inertia, 'bx-')
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method For Optimal k')
plt.show()

# From the elbow plot, choose the optimal number of clusters, e.g., 3
optimal_clusters = 3

# Apply KMeans clustering
kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

# Add the cluster labels to the original dataset
data['Cluster'] = clusters

# Define the output path and ensure the directory exists
output_dir = 'C:\\Users\\Yashmine Mela\\Downloads\\dataset capstone'
output_file = 'dataset-ayam_food_recipes_with_clusters.csv'

# Create the directory if it does not exist
os.makedirs(output_dir, exist_ok=True)

# Save the clustered data to a new CSV file
output_path = os.path.join(output_dir, output_file)
data.to_csv(output_path, index=False)

# Visualize the clusters
plt.figure(figsize=(8, 6))
sns.scatterplot(x='Loves', y='Loves', hue='Cluster', data=data, palette='viridis')
plt.title('Clusters of Indonesian Food Recipes')
plt.xlabel('Loves')
plt.ylabel('Loves')
plt.legend(title='Cluster')
plt.show()

# Display the first few rows of the dataset with cluster labels
print(data.head())

import pandas as pd
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import os

# Define the path to the dataset
dataset_path = '/content/dataset-tahu.csv'  # Replace with the actual CSV file name

# Load the dataset
data = pd.read_csv(dataset_path)

# Display the first few rows and columns of the dataset to understand its structure
print(data.head())
print(data.columns)

# Feature selection - select relevant features for clustering
# We will use the 'Loves' column for clustering
features = ['Loves']  # Replace with actual feature names if available

# Ensure the selected feature columns exist in the dataset
X = data[features]

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Determine the optimal number of clusters using the elbow method
inertia = []
K = range(1, 11)
for k in K:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    inertia.append(kmeans.inertia_)

# Plot the elbow curve
plt.figure(figsize=(8, 6))
plt.plot(K, inertia, 'bx-')
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method For Optimal k')
plt.show()

# From the elbow plot, choose the optimal number of clusters, e.g., 3
optimal_clusters = 3

# Apply KMeans clustering
kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

# Add the cluster labels to the original dataset
data['Cluster'] = clusters

# Define the output path and ensure the directory exists
output_dir = 'C:\\Users\\Yashmine Mela\\Downloads\\dataset capstone'
output_file = 'dataset-ayam_food_recipes_with_clusters.csv'

# Create the directory if it does not exist
os.makedirs(output_dir, exist_ok=True)

# Save the clustered data to a new CSV file
output_path = os.path.join(output_dir, output_file)
data.to_csv(output_path, index=False)

# Visualize the clusters
plt.figure(figsize=(8, 6))
sns.scatterplot(x='Loves', y='Loves', hue='Cluster', data=data, palette='viridis')
plt.title('Clusters of Indonesian Food Recipes')
plt.xlabel('Loves')
plt.ylabel('Loves')
plt.legend(title='Cluster')
plt.show()

# Display the first few rows of the dataset with cluster labels
print(data.head())

import pandas as pd
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import os

# Define the path to the dataset
dataset_path = '/content/dataset-tempe.csv'  # Replace with the actual CSV file name

# Load the dataset
data = pd.read_csv(dataset_path)

# Display the first few rows and columns of the dataset to understand its structure
print(data.head())
print(data.columns)

# Feature selection - select relevant features for clustering
# We will use the 'Loves' column for clustering
features = ['Loves']  # Replace with actual feature names if available

# Ensure the selected feature columns exist in the dataset
X = data[features]

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Determine the optimal number of clusters using the elbow method
inertia = []
K = range(1, 11)
for k in K:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    inertia.append(kmeans.inertia_)

# Plot the elbow curve
plt.figure(figsize=(8, 6))
plt.plot(K, inertia, 'bx-')
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method For Optimal k')
plt.show()

# From the elbow plot, choose the optimal number of clusters, e.g., 3
optimal_clusters = 3

# Apply KMeans clustering
kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

# Add the cluster labels to the original dataset
data['Cluster'] = clusters

# Define the output path and ensure the directory exists
output_dir = 'C:\\Users\\Yashmine Mela\\Downloads\\dataset capstone'
output_file = 'dataset-ayam_food_recipes_with_clusters.csv'

# Create the directory if it does not exist
os.makedirs(output_dir, exist_ok=True)

# Save the clustered data to a new CSV file
output_path = os.path.join(output_dir, output_file)
data.to_csv(output_path, index=False)

# Visualize the clusters
plt.figure(figsize=(8, 6))
sns.scatterplot(x='Loves', y='Loves', hue='Cluster', data=data, palette='viridis')
plt.title('Clusters of Indonesian Food Recipes')
plt.xlabel('Loves')
plt.ylabel('Loves')
plt.legend(title='Cluster')
plt.show()

# Display the first few rows of the dataset with cluster labels
print(data.head())

import pandas as pd
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import os

# Define the path to the dataset
dataset_path = '/content/dataset-telur.csv'  # Replace with the actual CSV file name

# Load the dataset
data = pd.read_csv(dataset_path)

# Display the first few rows and columns of the dataset to understand its structure
print(data.head())
print(data.columns)

# Feature selection - select relevant features for clustering
# We will use the 'Loves' column for clustering
features = ['Loves']  # Replace with actual feature names if available

# Ensure the selected feature columns exist in the dataset
X = data[features]

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Determine the optimal number of clusters using the elbow method
inertia = []
K = range(1, 11)
for k in K:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    inertia.append(kmeans.inertia_)

# Plot the elbow curve
plt.figure(figsize=(8, 6))
plt.plot(K, inertia, 'bx-')
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method For Optimal k')
plt.show()

# From the elbow plot, choose the optimal number of clusters, e.g., 3
optimal_clusters = 3

# Apply KMeans clustering
kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

# Add the cluster labels to the original dataset
data['Cluster'] = clusters

# Define the output path and ensure the directory exists
output_dir = 'C:\\Users\\Yashmine Mela\\Downloads\\dataset capstone'
output_file = 'dataset-ayam_food_recipes_with_clusters.csv'

# Create the directory if it does not exist
os.makedirs(output_dir, exist_ok=True)

# Save the clustered data to a new CSV file
output_path = os.path.join(output_dir, output_file)
data.to_csv(output_path, index=False)

# Visualize the clusters
plt.figure(figsize=(8, 6))
sns.scatterplot(x='Loves', y='Loves', hue='Cluster', data=data, palette='viridis')
plt.title('Clusters of Indonesian Food Recipes')
plt.xlabel('Loves')
plt.ylabel('Loves')
plt.legend(title='Cluster')
plt.show()

# Display the first few rows of the dataset with cluster labels
print(data.head())

import pandas as pd
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import os

# Define the path to the dataset
dataset_path = '/content/dataset-ikan.csv'  # Replace with the actual CSV file name

# Load the dataset
data = pd.read_csv(dataset_path)

# Display the first few rows and columns of the dataset to understand its structure
print(data.head())
print(data.columns)

# Feature selection - select relevant features for clustering
# We will use the 'Loves' column for clustering
features = ['Loves']  # Replace with actual feature names if available

# Ensure the selected feature columns exist in the dataset
X = data[features]

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Determine the optimal number of clusters using the elbow method
inertia = []
K = range(1, 11)
for k in K:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    inertia.append(kmeans.inertia_)

# Plot the elbow curve
plt.figure(figsize=(8, 6))
plt.plot(K, inertia, 'bx-')
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method For Optimal k')
plt.show()

# From the elbow plot, choose the optimal number of clusters, e.g., 3
optimal_clusters = 3

# Apply KMeans clustering
kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

# Add the cluster labels to the original dataset
data['Cluster'] = clusters

# Define the output path and ensure the directory exists
output_dir = 'C:\\Users\\Yashmine Mela\\Downloads\\dataset capstone'
output_file = 'dataset-ayam_food_recipes_with_clusters.csv'

# Create the directory if it does not exist
os.makedirs(output_dir, exist_ok=True)

# Save the clustered data to a new CSV file
output_path = os.path.join(output_dir, output_file)
data.to_csv(output_path, index=False)

# Visualize the clusters
plt.figure(figsize=(8, 6))
sns.scatterplot(x='Loves', y='Loves', hue='Cluster', data=data, palette='viridis')
plt.title('Clusters of Indonesian Food Recipes')
plt.xlabel('Loves')
plt.ylabel('Loves')
plt.legend(title='Cluster')
plt.show()

# Display the first few rows of the dataset with cluster labels
print(data.head())